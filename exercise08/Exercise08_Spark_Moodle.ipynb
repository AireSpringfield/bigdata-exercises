{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for the moodle exercise in Spark\n",
    "\n",
    "In this jupyter notebook we are going to make the preprocessing part of the dataset that is going to be used in the graded exercise of this week.\n",
    "1. Change to exercise08 repository\n",
    "\n",
    "2. Start docker <br>\n",
    "docker-compose up -d\n",
    "\n",
    "3. Getting the data:\n",
    "Follow the procedure that is described below. The dataset can be found here: http://data.greatlanguagegame.com.s3.amazonaws.com/confusion-2014-03-02.tbz2. More specifically do the following:\n",
    "- download the data      :<br> ```wget http://data.greatlanguagegame.com.s3.amazonaws.com/confusion-2014-03-02.tbz2```\n",
    "- extract the data       :<br> ```tar -jxvf confusion-2014-03-02.tbz2```\n",
    "\n",
    "4. copy the data to hdfs :<br> ```docker cp confusion-2014-03-02/confusion-2014-03-02.json jupyter:/home/jovyan/work``` <br>\n",
    "(Copying the data to hdfs needs to be done only once and it might take 1-2 minutes.)\n",
    "\n",
    "## More Info about the data\n",
    "You can find more information about the dataset (as well as the schema and examples) in this link: http://lars.yencken.org/datasets/languagegame/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing commands\n",
    "In your newly created notebook run these commands in order to have the dataset into an RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "spark = SparkSession.builder.master('local').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "path = \"confusion-2014-03-02.json\"\n",
    "raw_data = sc.textFile(path)\n",
    "dataset = raw_data.map(json.loads).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that you will be able to run the queries of the moodle question of this week. The RDD that you have to perform your queries on is the ```dataset``` one. For example, the following command returns one element of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'guess': 'Norwegian',\n",
       "  'target': 'Norwegian',\n",
       "  'country': 'AU',\n",
       "  'choices': ['Maori', 'Mandarin', 'Norwegian', 'Tongan'],\n",
       "  'sample': '48f9c924e0d98c959d8a6f1862b3ce9a',\n",
       "  'date': '2013-08-19'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions:\n",
    "\n",
    "In every query we ask you for three quantities: the query itself, the result of the query as well as the productivity time. That means the development time of each query (time elapsed before you start writing the query, and the time at which the correct, final query is ready). Note that the time part of every question is optional and not graded. In order to make easier the time recording we created two functions that do it automatically. Run the cell below in order to import the functions into the current notebook. Then before each query we will have a ```start_exercise()``` cell that you have to run in order to start time recording. After you have finished your query and you are sure about the answer run the ```finish_exercise()``` one to get the time measurement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def start_exercise():\n",
    "    global last\n",
    "    last = time.time()\n",
    "    \n",
    "def finish_exercise():\n",
    "    global last\n",
    "    print(\"This exercise took {0}s\".format(int(time.time()-last)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to have a part of the dataset in order to run faster experiments then run the cell below and run your queries against the ```dataset_part``` RDD. However your final answer, the format of your final query and the productivity time should be run/measured against the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_part = dataset.sample(False, 0.0001).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "Find the number of games where the guessed language is correct (meaning equal to the target one) and that language is Russian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290818"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This exercise took 119s\n",
    "# games_correct = dataset.filter(lambda game:game['guess']==game['target'])\n",
    "# print(games_correct.take(5))\n",
    "# print(games_correct.count())\n",
    "dataset.filter(lambda game:game['guess']==game['target'] and game['target']=='Russian').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 119s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "Return the number of distinct \"target\" languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albanian', 'Slovenian', 'Tigrinya', 'Northern Ndebele', 'Japanese']\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "# This exercise took 170s\n",
    "# target_langs = dataset.map(lambda game : game['target'])\n",
    "# distinct_langs = target_langs.distinct()\n",
    "# print(distinct_langs.take(5))\n",
    "# print(distinct_langs.count())\n",
    "dataset.map(lambda game : game['target']).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 170s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "Return the sample IDs (i.e., the *sample* field) of the top three games where the guessed language is correct (equal to the target one) ordered by language (ascending), then by country (ascending), then by date (ascending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Macedonian'],\n",
       "  'sample': '00b85faa8b878a14f8781be334deb137',\n",
       "  'date': '2013-09-04'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Bulgarian', 'Indonesian', 'Portuguese'],\n",
       "  'sample': 'efcd813daec1c836d9f030b30caa07ce',\n",
       "  'date': '2013-09-05'},\n",
       " {'guess': 'Albanian',\n",
       "  'target': 'Albanian',\n",
       "  'country': 'A1',\n",
       "  'choices': ['Albanian', 'Hindi', 'Swahili'],\n",
       "  'sample': '13722ceed1eede7ba597ade9b4cb9807',\n",
       "  'date': '2013-09-08'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This exercise took 1928s\n",
    "dataset.filter(lambda game:game['guess']==game['target']).sortBy(lambda game : (game['language'], game['country'], game['date']), ascending=True).map(game : game['sample']).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 1928s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "Aggregate all games by country and target language, counting the number of guesses for each group and return the frequencies of the three most frequent country/language combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('US', 'French'), 112934),\n",
       " (('US', 'German'), 112007),\n",
       " (('US', 'Spanish'), 110919)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This exercise took 744s\n",
    "dataset.groupBy(lambda game : (game['country'], game['target'])).map(lambda x : (x[0], sum(1 for _ in x[1]))).sortBy(lambda y : y[1], ascending=False).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 744s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 5\n",
    "Find the percentage of games where (the answer was correct && the correct guess was the first choice amongst the array of possible answers)\n",
    "\n",
    "Please write the fraction rounding to 4 decimals (eg. 0.3323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25603983084476356"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This exercise took 235s\n",
    "dataset.filter(lambda game:game['guess']==game['target'] and game['guess']==game['choices'][0]).count() / dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 235s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "Sort the languages by decreasing overall percentage of correct guesses and return the first three languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('French', 0.9382414927447232),\n",
       " ('German', 0.9197634593055483),\n",
       " ('Spanish', 0.8956432115670598)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This exercise took 693s\n",
    "dataset.map(lambda game : (game['target'] , 1 if game['target']==game['guess'] else 0)).groupByKey().map(lambda x : (x[0], sum(x[1])/sum(1 for _ in x[1]))).sortBy(lambda y:y[1], ascending=False).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 693s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 7\n",
    "Return the number games played on the latest day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exercise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65653"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This exercise took 124s\n",
    "latest_date = dataset.map(lambda game : game['date']).reduce(lambda x, y: max(x,y)); dataset.filter(lambda game: game['date']==latest_date).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This exercise took 124s\n"
     ]
    }
   ],
   "source": [
    "finish_exercise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
